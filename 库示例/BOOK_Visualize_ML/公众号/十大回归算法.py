
"""

最强总结，十大回归算法核心公式
https://mp.weixin.qq.com/s?__biz=MzkwNjY5NDU2OQ==&mid=2247484032&idx=1&sn=2ef69f9e0887d2858cd2846b5d84060d&chksm=c0e5d846f79251502057bf0c6e0935888d9174b37a0bfde0bacb6cd3c077d95afc204cce50a3&mpshare=1&scene=1&srcid=0726TPMnjSNHlrkOYYKuAWCy&sharer_shareinfo=c7bea49407dc008c2aab0f3721688821&sharer_shareinfo_first=c7bea49407dc008c2aab0f3721688821&exportkey=n_ChQIAhIQ0Cg%2BHOAreIQ1WLguWgxu0xKSAgIE97dBBAEAAAAAAMQkJvd6IckAAAAOpnltbLcz9gKNyK89dVj0i9wxIjZ5jhW1hQ%2FzeuEdaPBubB56HvfjaNIu%2FE2WlchMZkNvpCTKWAM8ehX0Bwn%2F%2Bn0Gllsm1QmsgrCgxtr7auz5%2FZKAtMdC%2BWPh0qGcVI7LOlVflIuxv1HlaOjVy6jXWaHhVTjzET33%2B55pB4Vi85lJYH2hjpFiRQmpQkK32nKXucmV8ThIauCNGyBGzvLKX8Uul41hAhyYV2Q9gXRmFzq4lS7KD2Kkl2SKZ3QHtEMQmNuaaVtcuJu7l%2B0wE3nJzs4AXKhjxu%2FH4Ihp8y5Qfeh1k9HAv%2B0VjgkSYS17KtJqySCICovTCcLcNCU%3D&acctmode=0&pass_ticket=akRwruQaQHbUHlYyJoWpqkdyRpyRViPQjUIUZCUuB61UVwuHmShJqfmT44Qc%2BC9n&wx_header=0#rd

通透！十大回归算法全总结！
https://mp.weixin.qq.com/s?__biz=Mzk0MjUxMzg3OQ==&mid=2247486033&idx=1&sn=1c6ad89d9cb7923dfc58554184d7dc1f&chksm=c2c341e9f5b4c8ff84123e2159f8511587cceee966844b48b38c643f70ff3d0c8f47a0ff47a7&mpshare=1&scene=1&srcid=0726ta8LXP8xzLdqpJhhZiB3&sharer_shareinfo=40f1a55d93656485fd0ae74dac3ce470&sharer_shareinfo_first=40f1a55d93656485fd0ae74dac3ce470&exportkey=n_ChQIAhIQJ4ZsK%2FLMOR8wyFoB2fY9hBKQAgIE97dBBAEAAAAAAOGLIrpxJpEAAAAOpnltbLcz9gKNyK89dVj0%2FKyDTcgdn0zuf0vguhOdv6Ib0SELpfWt93ag7x4GLmyW9KX3f2vqQ4OnB3dDaHrrFnT4mBr9UXIjgNuoz6avloTSZKWhzWTTLBxnitGmTu085v7kcF%2FoL4kmYo9R57%2FqXVN6n9V%2FR8HdfLAHvCiF4Pmxoxk4wB92Oe0bvB5kb8rZl3uw4ydATqEUu3Z%2FXEJnxcAWCF8X6TOHp6UbYJjKy2IVmFEoYBSWTze%2F1zIYVg7e%2B8rLuHIoBm9XVjrhpbf8wzXlrM9%2BOQTLVfYSUCb20u3StWnVvTFDRjBnWPOEbA1veLvKdxdDXhTX&acctmode=0&pass_ticket=HClY0DMZAVhWlVUAS38Y60hCN09JIO9gbO83ddMztht%2FwZF3fZtFu1wldf4L6w05&wx_header=0#rd

最强总结，十大回归算法
https://mp.weixin.qq.com/s?__biz=MzkwNjY5NDU2OQ==&mid=2247484158&idx=1&sn=49656b0ca74b7ae77e6cb2937c21bda8&chksm=c0e5d838f792512e7f75de7132da37fe6b0fa9cb9b88d63a8d51c48b6cc4887f4a2e9a5efff4&mpshare=1&scene=24&srcid=0726X7VLbaYJck1popaMp0xg&sharer_shareinfo=522a1db1b91390f858bdc17bf78eb673&sharer_shareinfo_first=522a1db1b91390f858bdc17bf78eb673&exportkey=n_ChQIAhIQpCyLHQS%2F5vQCZve8C4PcORKfAgIE97dBBAEAAAAAACPtA%2F6ALIYAAAAOpnltbLcz9gKNyK89dVj0g1UjtUuokWEGXG%2BN4gATITUmtfK0N%2FRxE%2FgxHBZcWiylcKaQpAw71ochOhthdA7gqhix2MsIGHKdo3xlYtn2tod%2BMK3u5n%2B0A7jgR5DXnhyh46vlaiRvFu03IZzLK6Umr8UDj5FbZC1ez5f2t7IyM4rBs4vEnEKFEKdjHW9GJvHqMrFpiiOD85D3duLUC9MRcrzHQyKmh16Rh%2BP%2Fgu3pB4J2ga1iYp%2FZ0E84mleSPpUDc3e3TSnb%2B8fACAdcu8hn3vgZarwue7UT9gTOxJ5wFHhFNcad9ioz1ufLQ1PL%2BLbrefllhdN0zwMHael37Jv1hI%2BvZWMJmt%2F8&acctmode=0&pass_ticket=A%2Bavg7BGsevCLBiWSqA7MW3PxXyPNjtSWN7QDwNYJCRhUbYkAE8xL4N8WneKTHX%2F&wx_header=0#rd





"""
#%% 1. 线性回归 (Linear Regression)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 生成随机数据
np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# 线性回归模型
lin_reg = LinearRegression()
lin_reg.fit(X, y)
y_pred = lin_reg.predict(X)

# 绘图
plt.scatter(X, y, color='blue', label='Data points')
plt.plot(X, y_pred, color='red', label='Regression line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear Regression')
plt.legend()
plt.show()




#%% 2. 岭回归 (Ridge Regression)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge

# 生成随机数据
np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# 岭回归模型
ridge_reg = Ridge(alpha=1, solver="cholesky")
ridge_reg.fit(X, y)
y_pred = ridge_reg.predict(X)

# 绘图
plt.scatter(X, y, color='blue', label='Data points')
plt.plot(X, y_pred, color='red', label='Ridge regression line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Ridge Regression')
plt.legend()
plt.show()




#%% 3. lasso回归 (Lasso Regression)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Lasso

# 生成随机数据
np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# 拉索回归模型
lasso_reg = Lasso(alpha=0.1)
lasso_reg.fit(X, y)
y_pred = lasso_reg.predict(X)

# 绘图
plt.scatter(X, y, color='blue', label='Data points')
plt.plot(X, y_pred, color='red', label='Lasso regression line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Lasso Regression')
plt.legend()
plt.show()




#%% 4. 弹性网络回归 (Elastic Net Regression)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import ElasticNet

# 生成随机数据
np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# 弹性网络回归模型
elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic_net.fit(X, y)
y_pred = elastic_net.predict(X)

# 绘图
plt.scatter(X, y, color='blue', label='Data points')
plt.plot(X, y_pred, color='red', label='Elastic Net regression line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Elastic Net Regression')
plt.legend()
plt.show()




#%% 5. 多项式回归 (Polynomial Regression)
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# 生成随机数据
np.random.seed(0)
X = 6 * np.random.rand(100, 1) - 3
y = 0.5 * X**2 + X + 2 + np.random.randn(100, 1)

# 多项式特征变换
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X)

# 线性回归模型
lin_reg = LinearRegression()
lin_reg.fit(X_poly, y)
y_pred = lin_reg.predict(X_poly)

# 绘图
plt.scatter(X, y, color='blue', label='Data points')
plt.plot(X, y_pred, color='red', label='Polynomial regression line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Polynomial Regression')
plt.legend()
plt.show()




#%% 6. 支持向量回归 (Support Vector Regression, SVR)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR

# 生成随机数据
np.random.seed(0)
X = 6 * np.random.rand(100, 1) - 3
y = 0.5 * X**2 + X + 2 + np.random.randn(100, 1)

# 支持向量回归模型
svr = SVR(kernel='rbf', C=100, epsilon=0.1)
svr.fit(X, y.ravel())
y_pred = svr.predict(X)

# 绘图
plt.scatter(X, y, color='blue', label='Data points')
plt.plot(X, y_pred, color='red', label='SVR regression line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Support Vector Regression')
plt.legend()
plt.show()


#%% 7. 决策树回归 (Decision Tree Regression)

# 导入所需的库
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor, plot_tree

# 创建一个虚拟数据集
np.random.seed(0)
X = np.sort(5 * np.random.rand(80, 1), axis=0)
y = np.sin(X).ravel()
y[::5] += 3 * (0.5 - np.random.rand(16))  # 添加噪声

# 训练回归模型
regressor = DecisionTreeRegressor(max_depth=5)
regressor.fit(X, y)

# 绘制决策树图像
plt.figure(figsize=(10, 8))
plot_tree(regressor, filled=True)
plt.title("Decision Tree Regression")
plt.show()




#%% 8. 随机森林回归 (Random Forest Regression)
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.ensemble import RandomForestRegressor

X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)

# 训练随机森林回归模型
regressor = RandomForestRegressor(n_estimators=100, random_state=42)
regressor.fit(X, y)

# 预测结果
X_test = np.linspace(-3, 3, 100).reshape(-1, 1)
y_pred = regressor.predict(X_test)

# 绘制随机森林中的一棵决策树图像
estimator = regressor.estimators_[0]

plt.figure(figsize=(10, 8))
plt.scatter(X, y, color="b", s=30, marker="o", label="training data")
plt.plot(X_test, y_pred, color="r", label="predictions")
plt.title("Random Forest Regression")
plt.xlabel("Feature")
plt.ylabel("Target")
plt.legend(loc="upper left")

# 可视化一棵决策树
plt.figure(figsize=(15, 10))
from sklearn.tree import plot_tree
plot_tree(estimator, filled=True, feature_names=['Feature'])
plt.title("Example Decision Tree from Random Forest")
plt.show()




#%% 9. 梯度提升回归 (Gradient Boosting Regression)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingRegressor

# 创建一个非线性函数作为模拟数据
def true_function(x):
    return np.sin(x) + np.sin(10 * x)

# 生成模拟数据
np.random.seed(0)
X = np.sort(5 * np.random.rand(200, 1), axis=0)
y = true_function(X).ravel()
dy = 0.5 + 1.0 * np.random.rand(200)
y += np.random.normal(0, dy)

# 拟合梯度提升回归模型
est = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0, loss='squared_error')
est.fit(X, y,  )

# 生成预测数据
X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]
y_pred = est.predict(X_test)

# 绘制结果
plt.figure(figsize=(10, 6))
plt.errorbar(X.ravel(), y, dy, fmt='o', alpha=0.5, label='Observations')
plt.plot(X_test, true_function(X_test), label='True function', color='blue')
plt.plot(X_test, y_pred, '--', color='navy', label='Predicted function')
plt.fill_between(X_test.ravel(), y_pred - est.estimators_[0][0].predict(X_test), y_pred + est.estimators_[0][0].predict(X_test), color='red', alpha=0.6, label='Uncertainty')
plt.title('Gradient Boosting Regression')
plt.legend(loc='upper left')
plt.xlabel('X')
plt.ylabel('y')
plt.show()


#%% 10. 贝叶斯回归 (Bayesian Regression)
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import BayesianRidge

# 创建一个非线性函数作为模拟数据
def true_function(x):
    return np.sin(x) + np.sin(2 * x) + np.sin(3 * x)

# 生成模拟数据
np.random.seed(0)
X = np.sort(5 * np.random.rand(200, 1), axis=0)
y = true_function(X).ravel()
dy = 0.5 + 1.0 * np.random.rand(200)
y += np.random.normal(0, dy)

# 贝叶斯线性回归模型
poly = PolynomialFeatures(degree=5)
X_poly = poly.fit_transform(X)
clf = BayesianRidge(compute_score=True)
clf.fit(X_poly, y)

# 生成预测数据
X_test = np.linspace(0, 5, 100)[:, np.newaxis]
y_pred, y_std = clf.predict(poly.transform(X_test), return_std=True)

# 绘制结果
plt.figure(figsize=(10, 6))
plt.errorbar(X.ravel(), y, dy, fmt='o', alpha=0.5, label='Observations')
plt.plot(X_test, true_function(X_test), color='green', label='True function')
plt.plot(X_test, y_pred, '--', color='navy', label='Predicted function')
plt.fill_between(X_test.ravel(), y_pred - y_std, y_pred + y_std, color='red', alpha=0.6, label='Uncertainty')
plt.title('Bayesian Regression with Polynomial Features')
plt.legend(loc='upper left')
plt.xlabel('X')
plt.ylabel('y')
plt.show()






















