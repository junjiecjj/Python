#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Jun 20 17:57:13 2022

@author: jack
"""






"""
def unfold(input, kernel_size, dilation=1, padding=0, stride=1):

    input: tensor数据，四维， Batchsize, channel, height, width
    kernel_size: 核大小，决定输出tensor的数目。稍微详细讲
    dilation: 输出形式是否有间隔，稍后详细讲。
    padding：一般是没有用的必要
    stride： 核的滑动步长。稍后详细讲
    
    https://blog.csdn.net/qq_34914551/article/details/102940368
    
    我们想将这个特征图连续的在分辨率维度（H和W）维度取出特征。就像下面这样：
    这里要说明一下，unfold函数的输入数据是四维，但输出是三维的。假设输入数据是[B, C, H, W], 那么输出数据是 [B, C* kH * kW, L], 其中kH是核的高，kW是核宽。 
    L则是这个高kH宽kW的核能在H*W区域按照指定stride滑动的次数。

    上面公式中第一项是指核高kH的情况下，能在高H的特征图上滑动的次数，后一项则是在宽这个维度上。当然默认stride=1
    得到的这三维tensor，还需要reshape一下，才能得到上图右边的形式。

"""

#================================================================================
#  stride=1
#=================================================================================


import torch
from torch.nn import functional as f

batchszie = 1
C = 3
H = 5
W = 5

x = torch.arange(0, batchszie*C*H*W).float()
x = x.view(batchszie,C,H,W)

# print(f"x = \n{x}")

print(f"x.shape = {x.shape}")

kernelsize = 2
stride = 1
x1 = f.unfold(x, kernel_size=kernelsize, dilation=1, stride=stride)
print(f"x1.shape = {x1.shape}")
B, C_kh_kw, L = x1.size()

#===========================================================================
x2 = x1.permute(0, 2, 1)
print(f"x2.shape = {x2.shape}")

x3 = x2.view(B, L, -1, kernelsize, kernelsize)
print(f"x3.shape = {x3.shape}")

# x.shape = torch.Size([1, 3, 5, 5])
# x1.shape = torch.Size([1, 12, 16])
# x2.shape = torch.Size([1, 16, 12])
# x3.shape = torch.Size([1, 16, 3, 2, 2])

#===========================================================================
x2 = x1.transpose(0,2).contiguous()
print(f"x2.shape = {x2.shape}")

x3 = x2.view(x2.size(0),-1,kernelsize,kernelsize)
print(f"x3.shape = {x3.shape}")

# x2.shape = torch.Size([16, 12, 1])
# x3.shape = torch.Size([16, 3, 2, 2])
#===========================================================================


x3 = x1.transpose(1,2).transpose(0,1).contiguous()
print(f"x3.shape = {x3.shape}")


x4 = x1.permute(2, 0, 1)
print(f"x4.shape = {x4.shape}")


x5 = x1.transpose(0,2)
print(f"x5.shape = {x5.shape}")
# x1.shape = torch.Size([1, 12, 16])
# x3.shape = torch.Size([16, 1, 12])
# x4.shape = torch.Size([16, 1, 12])
# x5.shape = torch.Size([16, 12, 1])

#================================================================================
#  stride=2
#=================================================================================


batchszie = 1
C = 3
H = 7
W = 7

x = torch.arange(0, batchszie*C*H*W).float()
x = x.view(batchszie,C,H,W)

# print(f"x = \n{x}")

print(f"x.shape = {x.shape}")

kernelsize = 2
stride = 2
x1 = f.unfold(x, kernel_size=kernelsize, dilation=1, stride=stride)
print(f"x1.shape = {x1.shape}")
B, C_kh_kw, L = x1.size()


x2 = x1.permute(0, 2, 1)
print(f"x2.shape = {x2.shape}")

x3 = x2.view(B, L, -1, kernelsize, kernelsize)
print(f"x3.shape = {x3.shape}")



#================================================================================
#  stride=12
#=================================================================================

batchszie = 1
C = 3
H = 256
W = 256

x = torch.arange(0, batchszie*C*H*W).float()
x = x.view(batchszie,C,H,W)

# print(f"x = \n{x}")

print(f"x.shape = {x.shape}")

kernelsize = 48
stride = 12
x1 = f.unfold(x, kernelsize,  stride=stride).transpose(0,2).contiguous()
print(f"x1.shape = {x1.shape}")






#================================================================================
#   unfold
#=================================================================================


import torch
from torch.nn import functional as f
import torch.nn as nn

batchszie = 1
C = 3
H = 5
W = 5

x = torch.arange(0, 1*3*5*5).float()
x = x.view(batchszie,C,H,W)
print(f"x.shape = {x.shape}")
print(f"x = \n{x}")


unfold = nn.Unfold(kernel_size=(2,2),dilation=1,padding=0,stride= (1,1))
x1 = unfold(x)
print(f"x1.shape = {x1.shape}")
print(f"x1  = {x1}")

# x.shape = torch.Size([1, 3, 5, 5])
# x1.shape = torch.Size([1, 12, 16])

# 2.nn.Fold(）函数
# 该函数是nn.Unfold()函数的逆操作。

fold = torch.nn.Fold(output_size=(5, 5), kernel_size=(2, 2), dilation=1,padding=0,stride=1)
X = fold(x1)
print(f"X = {X}")
print(f"X.shape = {X.shape}")

# x.shape = torch.Size([1, 3, 5, 5])
# x = 
# tensor([[[[ 0.,  1.,  2.,  3.,  4.],
#           [ 5.,  6.,  7.,  8.,  9.],
#           [10., 11., 12., 13., 14.],
#           [15., 16., 17., 18., 19.],
#           [20., 21., 22., 23., 24.]],

#          [[25., 26., 27., 28., 29.],
#           [30., 31., 32., 33., 34.],
#           [35., 36., 37., 38., 39.],
#           [40., 41., 42., 43., 44.],
#           [45., 46., 47., 48., 49.]],

#          [[50., 51., 52., 53., 54.],
#           [55., 56., 57., 58., 59.],
#           [60., 61., 62., 63., 64.],
#           [65., 66., 67., 68., 69.],
#           [70., 71., 72., 73., 74.]]]])
# x1.shape = torch.Size([1, 12, 16])
# x1  = tensor([[[ 0.,  1.,  2.,  3.,  5.,  6.,  7.,  8., 10., 11., 12., 13., 15., 16.,
#           17., 18.],
#          [ 1.,  2.,  3.,  4.,  6.,  7.,  8.,  9., 11., 12., 13., 14., 16., 17.,
#           18., 19.],
#          [ 5.,  6.,  7.,  8., 10., 11., 12., 13., 15., 16., 17., 18., 20., 21.,
#           22., 23.],
#          [ 6.,  7.,  8.,  9., 11., 12., 13., 14., 16., 17., 18., 19., 21., 22.,
#           23., 24.],
#          [25., 26., 27., 28., 30., 31., 32., 33., 35., 36., 37., 38., 40., 41.,
#           42., 43.],
#          [26., 27., 28., 29., 31., 32., 33., 34., 36., 37., 38., 39., 41., 42.,
#           43., 44.],
#          [30., 31., 32., 33., 35., 36., 37., 38., 40., 41., 42., 43., 45., 46.,
#           47., 48.],
#          [31., 32., 33., 34., 36., 37., 38., 39., 41., 42., 43., 44., 46., 47.,
#           48., 49.],
#          [50., 51., 52., 53., 55., 56., 57., 58., 60., 61., 62., 63., 65., 66.,
#           67., 68.],
#          [51., 52., 53., 54., 56., 57., 58., 59., 61., 62., 63., 64., 66., 67.,
#           68., 69.],
#          [55., 56., 57., 58., 60., 61., 62., 63., 65., 66., 67., 68., 70., 71.,
#           72., 73.],
#          [56., 57., 58., 59., 61., 62., 63., 64., 66., 67., 68., 69., 71., 72.,
#           73., 74.]]])
# X = tensor([[[[  0.,   2.,   4.,   6.,   4.],
#           [ 10.,  24.,  28.,  32.,  18.],
#           [ 20.,  44.,  48.,  52.,  28.],
#           [ 30.,  64.,  68.,  72.,  38.],
#           [ 20.,  42.,  44.,  46.,  24.]],

#          [[ 25.,  52.,  54.,  56.,  29.],
#           [ 60., 124., 128., 132.,  68.],
#           [ 70., 144., 148., 152.,  78.],
#           [ 80., 164., 168., 172.,  88.],
#           [ 45.,  92.,  94.,  96.,  49.]],

#          [[ 50., 102., 104., 106.,  54.],
#           [110., 224., 228., 232., 118.],
#           [120., 244., 248., 252., 128.],
#           [130., 264., 268., 272., 138.],
#           [ 70., 142., 144., 146.,  74.]]]])
# X.shape = torch.Size([1, 3, 5, 5])


#================================================================================
#   unfold 
# https://www.codeleading.com/article/74735903442/
#=================================================================================


import torch
import torch.nn as nn

x = torch.Tensor([[[[  1,  2,  3,  4],
   					[  5,  6,  7,  8],
   					[  9, 10, 11, 12],
   					[ 13, 14, 15, 16]]]])

print(f"x = \n{x}")
print(f"x.shape = {x.shape}")
unfold = nn.Unfold((2,2), stride=2)


fold = nn.Fold(kernel_size=(2,2), stride=2, output_size=(4,4))
x1 = unfold(x) 
print(f"x1 = \n{x1}")
print(f"x1.shape = {x1.shape}")
x2 = fold(x1)
print(f"x2 = \n{x2}")
print(f"x2.shape = {x2.shape}")


# x = 
# tensor([[[[ 1.,  2.,  3.,  4.],
#           [ 5.,  6.,  7.,  8.],
#           [ 9., 10., 11., 12.],
#           [13., 14., 15., 16.]]]])
# x.shape = torch.Size([1, 1, 4, 4])
# x1 = 
# tensor([[[ 1.,  3.,  9., 11.],
#          [ 2.,  4., 10., 12.],
#          [ 5.,  7., 13., 15.],
#          [ 6.,  8., 14., 16.]]])
# x1.shape = torch.Size([1, 4, 4])
# x2 = 
# tensor([[[[ 1.,  2.,  3.,  4.],
#           [ 5.,  6.,  7.,  8.],
#           [ 9., 10., 11., 12.],
#           [13., 14., 15., 16.]]]])
# x2.shape = torch.Size([1, 1, 4, 4])


#===============================================================================
import torch
import torch.nn as nn

x = torch.Tensor([[[[  1,  2,  3,  4],
   					[  5,  6,  7,  8],
   					[  9, 10, 11, 12],
   					[ 13, 14, 15, 16]]]])

print(f"x = \n{x}")
print(f"x.shape = {x.shape}")
unfold = nn.Unfold((2,2), stride=1)


fold = nn.Fold(kernel_size=(2,2), stride=1, output_size=(4,4))
x1 = unfold(x) 
print(f"x1 = \n{x1}")
print(f"x1.shape = {x1.shape}")
x2 = fold(x1)
print(f"x2 = \n{x2}")
print(f"x2.shape = {x2.shape}")

# x = 
# tensor([[[[ 1.,  2.,  3.,  4.],
#           [ 5.,  6.,  7.,  8.],
#           [ 9., 10., 11., 12.],
#           [13., 14., 15., 16.]]]])
# x.shape = torch.Size([1, 1, 4, 4])
# x1 = 
# tensor([[[ 1.,  2.,  3.,  5.,  6.,  7.,  9., 10., 11.],
#          [ 2.,  3.,  4.,  6.,  7.,  8., 10., 11., 12.],
#          [ 5.,  6.,  7.,  9., 10., 11., 13., 14., 15.],
#          [ 6.,  7.,  8., 10., 11., 12., 14., 15., 16.]]])
# x1.shape = torch.Size([1, 4, 9])
# x2 = 
# tensor([[[[ 1.,  4.,  6.,  4.],
#           [10., 24., 28., 16.],
#           [18., 40., 44., 24.],
#           [13., 28., 30., 16.]]]])
# x2.shape = torch.Size([1, 1, 4, 4])

#===============================================================================
import torch
import torch.nn as nn

x = torch.Tensor([[[[  1,  2,  3,  4],
   					[  5,  6,  7,  8],
   					[  9, 10, 11, 12],
   					[ 13, 14, 15, 16]]]])

print(f"x = \n{x}")
print(f"x.shape = {x.shape}")
unfold = nn.Unfold((2,2), stride=2)
x1 = unfold(x) 
print(f"x1 = \n{x1}")
print(f"x1.shape = {x1.shape}")

fold = nn.Fold(kernel_size=(2,2), stride=1, output_size=(3,3))
x2 = fold(x1)
print(f"x2 = \n{x2}")
print(f"x2.shape = {x2.shape}")


# x = 
# tensor([[[[ 1.,  2.,  3.,  4.],
#           [ 5.,  6.,  7.,  8.],
#           [ 9., 10., 11., 12.],
#           [13., 14., 15., 16.]]]])
# x.shape = torch.Size([1, 1, 4, 4])
# x1 = 
# tensor([[[ 1.,  3.,  9., 11.],
#          [ 2.,  4., 10., 12.],
#          [ 5.,  7., 13., 15.],
#          [ 6.,  8., 14., 16.]]])
# x1.shape = torch.Size([1, 4, 4])
# x2 = 
# tensor([[[[ 1.,  5.,  4.],
#           [14., 34., 20.],
#           [13., 29., 16.]]]])
# x2.shape = torch.Size([1, 1, 3, 3])

#===============================================================================
import torch
import torch.nn as nn

x1 = torch.arange(1*27648*324).reshape(1,27648,324)*1.0
print(f"x1.shape = {x1.shape}")
fold = nn.Fold(kernel_size=96, stride=24, output_size=(504,504))
x2 = fold(x1)
#print(f"x2 = \n{x2}")
print(f"x2.shape = {x2.shape}")


#===============================================================================
import torch
import torch.nn as nn

x = torch.arange(1*3*6*6).reshape(1,3,6,6)*1.0

print(f"x = \n{x}")
print(f"x.shape = {x.shape}")
unfold = nn.Unfold((3,3), stride=3)


fold = nn.Fold(kernel_size=(3,3), stride=3, output_size=(6,6))
x1 = unfold(x) 
print(f"x1 = \n{x1}")
print(f"x1.shape = {x1.shape}")
x2 = fold(x1)
print(f"x2 = \n{x2}")
print(f"x2.shape = {x2.shape}")

# x = 
# tensor([[[[  0.,   1.,   2.,   3.,   4.,   5.],
#           [  6.,   7.,   8.,   9.,  10.,  11.],
#           [ 12.,  13.,  14.,  15.,  16.,  17.],
#           [ 18.,  19.,  20.,  21.,  22.,  23.],
#           [ 24.,  25.,  26.,  27.,  28.,  29.],
#           [ 30.,  31.,  32.,  33.,  34.,  35.]],

#          [[ 36.,  37.,  38.,  39.,  40.,  41.],
#           [ 42.,  43.,  44.,  45.,  46.,  47.],
#           [ 48.,  49.,  50.,  51.,  52.,  53.],
#           [ 54.,  55.,  56.,  57.,  58.,  59.],
#           [ 60.,  61.,  62.,  63.,  64.,  65.],
#           [ 66.,  67.,  68.,  69.,  70.,  71.]],

#          [[ 72.,  73.,  74.,  75.,  76.,  77.],
#           [ 78.,  79.,  80.,  81.,  82.,  83.],
#           [ 84.,  85.,  86.,  87.,  88.,  89.],
#           [ 90.,  91.,  92.,  93.,  94.,  95.],
#           [ 96.,  97.,  98.,  99., 100., 101.],
#           [102., 103., 104., 105., 106., 107.]]]])
# x.shape = torch.Size([1, 3, 6, 6])
# x1 = 
# tensor([[[  0.,   3.,  18.,  21.],
#          [  1.,   4.,  19.,  22.],
#          [  2.,   5.,  20.,  23.],
#          [  6.,   9.,  24.,  27.],
#          [  7.,  10.,  25.,  28.],
#          [  8.,  11.,  26.,  29.],
#          [ 12.,  15.,  30.,  33.],
#          [ 13.,  16.,  31.,  34.],
#          [ 14.,  17.,  32.,  35.],
#          [ 36.,  39.,  54.,  57.],
#          [ 37.,  40.,  55.,  58.],
#          [ 38.,  41.,  56.,  59.],
#          [ 42.,  45.,  60.,  63.],
#          [ 43.,  46.,  61.,  64.],
#          [ 44.,  47.,  62.,  65.],
#          [ 48.,  51.,  66.,  69.],
#          [ 49.,  52.,  67.,  70.],
#          [ 50.,  53.,  68.,  71.],
#          [ 72.,  75.,  90.,  93.],
#          [ 73.,  76.,  91.,  94.],
#          [ 74.,  77.,  92.,  95.],
#          [ 78.,  81.,  96.,  99.],
#          [ 79.,  82.,  97., 100.],
#          [ 80.,  83.,  98., 101.],
#          [ 84.,  87., 102., 105.],
#          [ 85.,  88., 103., 106.],
#          [ 86.,  89., 104., 107.]]])
# x1.shape = torch.Size([1, 27, 4])
# x2 = 
# tensor([[[[  0.,   1.,   2.,   3.,   4.,   5.],
#           [  6.,   7.,   8.,   9.,  10.,  11.],
#           [ 12.,  13.,  14.,  15.,  16.,  17.],
#           [ 18.,  19.,  20.,  21.,  22.,  23.],
#           [ 24.,  25.,  26.,  27.,  28.,  29.],
#           [ 30.,  31.,  32.,  33.,  34.,  35.]],

#          [[ 36.,  37.,  38.,  39.,  40.,  41.],
#           [ 42.,  43.,  44.,  45.,  46.,  47.],
#           [ 48.,  49.,  50.,  51.,  52.,  53.],
#           [ 54.,  55.,  56.,  57.,  58.,  59.],
#           [ 60.,  61.,  62.,  63.,  64.,  65.],
#           [ 66.,  67.,  68.,  69.,  70.,  71.]],

#          [[ 72.,  73.,  74.,  75.,  76.,  77.],
#           [ 78.,  79.,  80.,  81.,  82.,  83.],
#           [ 84.,  85.,  86.,  87.,  88.,  89.],
#           [ 90.,  91.,  92.,  93.,  94.,  95.],
#           [ 96.,  97.,  98.,  99., 100., 101.],
#           [102., 103., 104., 105., 106., 107.]]]])
# x2.shape = torch.Size([1, 3, 6, 6])

#===============================================================================
import torch
import torch.nn as nn

x = torch.arange(1*64*48*48).reshape(1,64,48,48)*1.0

#print(f"x = \n{x}")
print(f"x.shape = {x.shape}")
unfold = nn.Unfold((3,3), stride=3)


fold = nn.Fold(kernel_size=(3,3), stride=3, output_size=(48,48))
x1 = unfold(x) 
#print(f"x1 = \n{x1}")
print(f"x1.shape = {x1.shape}")
x2 = fold(x1)
#print(f"x2 = \n{x2}")
print(f"x2.shape = {x2.shape}")


# x.shape = torch.Size([1, 64, 48, 48])
# x1.shape = torch.Size([1, 576, 256])
# x2.shape = torch.Size([1, 64, 48, 48])




